{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6685a220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'ms_deisotope._c.averagine' averagine\n",
      "No module named 'ms_deisotope._c.scoring'\n",
      "No module named 'ms_deisotope._c.deconvoluter_base'\n",
      "No module named 'ms_deisotope._c.deconvoluter_base'\n",
      "No module named 'ms_deisotope._c.deconvoluter_base'\n"
     ]
    }
   ],
   "source": [
    "#Import all the necessary libraries\n",
    "import pymzml\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "import plotly.express as px\n",
    "from collections import defaultdict\n",
    "\n",
    "import plotly.io as pio\n",
    "import json\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "import warnings\n",
    "from IPython.display import display, Image, clear_output\n",
    "import time\n",
    "##Custom scripts\n",
    "from parsing_function import full_parse\n",
    "from parsing_function import filter_dataframe\n",
    "from parsing_function import hex_to_rgba_hex\n",
    "from parsing_function import json_to_string\n",
    "from parsing_function import prep_edge_R\n",
    "\n",
    "from plotting_functions import make_pie_chart_no_replicates\n",
    "\n",
    "from plotting_functions import average_pie_chart_no_repeats\n",
    "\n",
    "from plotting_functions import make_bar_plot_comparisons\n",
    "\n",
    "# dfdfplotting_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "773509d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Pre_folder = './DEMO/'\n",
    "\n",
    "Project_Folder =Pre_folder + 'demo_data/'\n",
    "file_name_to_save = 'demo_1_tolerance'\n",
    "\n",
    "custom_data=True\n",
    "\n",
    "tolerance = 0.1\n",
    "remove_std = True\n",
    "save_data= True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5dd4741",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder_name_to_save = Project_Folder+ 'Processed Results/'\n",
    "data_base_name_location = 'lipid_database/Lipid_Database.xlsx'\n",
    "mzml_folder = Project_Folder +\"mzml/\"\n",
    "Pre_edge_r_path = Project_Folder+\"Pre_EdgeR/\"\n",
    "plots_2_save_path = Project_Folder+\"Plots/\"\n",
    "label_file = Project_Folder+\"Labels/labels.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db6fd542",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Labels DF and Labels List\n",
    "labels_df = pd.read_csv(label_file)\n",
    "labels_list = list(labels_df)\n",
    "labels_list = labels_list +[\"Class\",\"Lipid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72fe4bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a44df1aad44d4f0087ac12e7289ac55d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Samples', options=('Blank', 'IPA_clean_clean_clean_clean', 'DOD94_F3_Female_WT_hippocamp…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a29bbed3d149f1a411ad551eb43cdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Assign Blank', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78eb325fa6a7485f9653c73a909b2ed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assuming labels_df is your DataFrame and 'Sample Name' is the column with instances you want to select from\n",
    "unique_samples = labels_df['Sample Name'].unique()\n",
    "\n",
    "# Create a dropdown selection widget with instances as options\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=unique_samples,\n",
    "    value=unique_samples[0],  # default value\n",
    "    description='Samples',\n",
    "    disabled=False,\n",
    ")\n",
    "display(dropdown)\n",
    "\n",
    "# Create a button to perform the assignment\n",
    "button = widgets.Button(description=\"Assign Blank\")\n",
    "display(button)\n",
    "\n",
    "# Output widget to display the selected sample name\n",
    "output = widgets.Output()\n",
    "display(output)\n",
    "\n",
    "# Global variable to store the selected sample name\n",
    "global blank_name\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    # Declare blank_name as global variable\n",
    "    global blank_name\n",
    "\n",
    "    # Assign the selected sample name to blank_name\n",
    "    blank_name = dropdown.value\n",
    "\n",
    "    # Display the selected sample name\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        print(f\"Blank is: {blank_name}\")\n",
    "\n",
    "button.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9cfa621",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b228d6943b154016a6650a681d657ca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Samples', index=(0,), options=('Blank', 'IPA_clean_clean_clean_clean', 'DOD94_F3_F…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7483752d345e46f1a3b4bfe2f5dd7b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Filter Samples', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ccd3ec6da2040e098209c53182b3d5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Assuming df is your DataFrame and 'Sample name' is the column with instances you want to filter\n",
    "unique_samples = labels_df['Sample Name'].unique()\n",
    "\n",
    "# Create a multiple selection widget with instances as options\n",
    "multi_select = widgets.SelectMultiple(\n",
    "    options=unique_samples,\n",
    "    value=[unique_samples[0]],  # default value\n",
    "    rows=len(unique_samples),\n",
    "    description='Samples',\n",
    "    disabled=False\n",
    ")\n",
    "display(multi_select)\n",
    "\n",
    "# Create a button to perform the filtering\n",
    "button = widgets.Button(description=\"Filter Samples\")\n",
    "display(button)\n",
    "\n",
    "# Output widget to display the resulting dataframe\n",
    "output = widgets.Output()\n",
    "display(output)\n",
    "\n",
    "# Global variable to store the new DataFrame\n",
    "global labels_df2\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    # Declare labels_df2 as global variable\n",
    "    global labels_df2\n",
    "    \n",
    "    # Clear the current output\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        \n",
    "    # Filter dataframe to exclude the selection\n",
    "    labels_df2 = labels_df[~labels_df['Sample Name'].isin(multi_select.value)]\n",
    "    \n",
    "    # Display the new dataframe\n",
    "    with output:\n",
    "        display(labels_df2)\n",
    "\n",
    "button.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afe5f1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df2 = labels_df2.drop([\"Sample Name\",\"Position\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfcae3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_json = {col: labels_df2[col].unique().tolist() for col in labels_df2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "457a76bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cage': ['DOD94', 'DOD93', 'FAD185', 'FAD184', 'FAD189'],\n",
       " 'Sex': ['Female', 'Male'],\n",
       " 'Genotype': ['WT', '5xFAD'],\n",
       " 'Brain Region': ['hippocampus', 'cortex ', 'cerebellum', 'diencephalon']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e20bb8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent imports\n",
    "from langchain.agents import create_json_agent, AgentExecutor, Tool\n",
    "from langchain.agents.agent_toolkits import JsonToolkit, FileManagementToolkit\n",
    "from langchain.agents.agent_toolkits.base import BaseToolkit\n",
    "from langchain.agents.conversational.base import ConversationalAgent\n",
    "\n",
    "# Tool imports\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.tools.human.tool import HumanInputRun\n",
    "from langchain.tools.json.tool import JsonGetValueTool, JsonListKeysTool, JsonSpec\n",
    "from langchain.tools.json.tool import JsonSpec\n",
    "from langchain.tools.file_management import (\n",
    "    ReadFileTool,\n",
    "    WriteFileTool,\n",
    "    ListDirectoryTool,\n",
    ")\n",
    "\n",
    "# LLM imports\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.requests import TextRequestsWrapper\n",
    "\n",
    "# Manager imports\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")\n",
    "\n",
    "# File managment imports\n",
    "from langchain.tools.file_management.utils import (\n",
    "    INVALID_PATH_TEMPLATE,\n",
    "    BaseFileToolMixin,\n",
    "    FileValidationError,\n",
    ")\n",
    "\n",
    "# Memory import\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# Typing + other imports\n",
    "from typing import List, Optional, Callable\n",
    "import json\n",
    "import ast\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f89f2139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom tools\n",
    "class JsonFilterFromKeysTool(BaseTool):\n",
    "    \n",
    "    def filter_json_nested(self, json_dict, keys_string, values_string):\n",
    "        # Parse keys_string and values_string into lists\n",
    "        keys = ast.literal_eval(keys_string)\n",
    "        values = ast.literal_eval(values_string)\n",
    "\n",
    "        filtered_dict = {}\n",
    "        for k, v in json_dict.items():\n",
    "            if k in keys:\n",
    "                # If value is a list, filter the list based on the allowed values\n",
    "                if isinstance(v, list):\n",
    "                    filtered_list = [item for item in v if item in values]\n",
    "                    if not filtered_list:\n",
    "                        return f\"Error: The list for key {k} is empty after filtering.\"\n",
    "                    filtered_dict[k] = filtered_list\n",
    "                elif isinstance(v, dict):\n",
    "                    filtered_dict[k] = filter_json_nested(v, keys_string, values_string)\n",
    "                elif v in values:  # For non-list, non-dict values\n",
    "                    filtered_dict[k] = v\n",
    "        return filtered_dict\n",
    "\n",
    "    name=\"json_filter_json_from_lists\"\n",
    "    description = \"\"\"Can be used to filter a JSON at a provided path based on provided keys and values.\n",
    "        Before calling this you should be SURE that the path to this exists.\n",
    "        The input is an exact text representation of two Python lists spearated by a semi colon where first list is the keys  to filter on, and the second list is the values to filter on.\n",
    "        An example is as follows '[\"key1\",\"key2\"];[\"value1\",\"value2\"]'\n",
    "    \"\"\"\n",
    "    spec: JsonSpec\n",
    "    \n",
    "    def _run(\n",
    "        self,\n",
    "        tool_input: str,\n",
    "        run_manager: Optional[CallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        return self.filter_json_nested(\n",
    "            self.spec.dict_,\n",
    "            tool_input.split(\";\")[0],\n",
    "            tool_input.split(\";\")[1]\n",
    "        )\n",
    "\n",
    "    async def _arun(\n",
    "        self,\n",
    "        tool_input: str,\n",
    "        run_manager: Optional[AsyncCallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        return self._run(tool_input)\n",
    "    \n",
    "class CustomWriteFileTool(BaseFileToolMixin, BaseTool):\n",
    "    \n",
    "    name: str = \"write_file\"\n",
    "    # args_schema: Type[BaseModel] = WriteFileInput\n",
    "    description: str = \"Write file to disk\"\n",
    "\n",
    "    def _run(\n",
    "        self,\n",
    "        info: str,\n",
    "        append: bool = False,\n",
    "        run_manager: Optional[CallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        file_path = str(ast.literal_eval(info)[\"path\"])\n",
    "        text = str(ast.literal_eval(info)[\"text\"])\n",
    "        try:\n",
    "            write_path = self.get_relative_path(file_path)\n",
    "        except FileValidationError:\n",
    "            return INVALID_PATH_TEMPLATE.format(arg_name=\"file_path\", value=file_path)\n",
    "        try:\n",
    "            write_path.parent.mkdir(exist_ok=True, parents=False)\n",
    "            mode = \"a\" if append else \"w\"\n",
    "            with write_path.open(mode, encoding=\"utf-8\") as f:\n",
    "                f.write(text)\n",
    "            return f\"File written successfully to {file_path}.\"\n",
    "        except Exception as e:\n",
    "            return \"Error: \" + str(e)\n",
    "\n",
    "    async def _arun(\n",
    "        self,\n",
    "        file_path: str,\n",
    "        text: str,\n",
    "        append: bool = False,\n",
    "        run_manager: Optional[AsyncCallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        # TODO: Add aiofiles method\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a612f96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "097bc995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our JSON spec\n",
    "json_spec = JsonSpec(dict_=main_json, max_value_length=4000)\n",
    "\n",
    "# Define our custom toolkit\n",
    "class CustomToolkit(BaseToolkit):\n",
    "      \n",
    "      spec: JsonSpec\n",
    "      \n",
    "      def get_tools(self) -> List[BaseTool]:\n",
    "          return [\n",
    "            JsonListKeysTool(spec=self.spec),\n",
    "            JsonGetValueTool(spec=self.spec),\n",
    "            JsonFilterFromKeysTool(spec=self.spec),\n",
    "            HumanInputRun(),\n",
    "            CustomWriteFileTool()\n",
    "          ]\n",
    "\n",
    "custom_toolkit = CustomToolkit(spec=json_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd86608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our prompt prefix and suffixes\n",
    "\n",
    "prefix = \"\"\"You are an agent designed to interact with a JSON and a human.\n",
    "\n",
    "Your overall goal is to interact with the user to create and save TWO (2) new filtered JSONs based on the original JSON.\n",
    "During interaction with the human prior to your final answer, they may ask for information about the keys or values of the JSON which you should provide to them.\n",
    "You should talk like a cat when responding, make sure to use lots of meows.\n",
    "\n",
    "DO NOT return your final answer until you use the write_file tool twice successfully to save off TWO (2) new JSONs. \n",
    "\n",
    "You have access to the following tools which help you learn more about the JSON you are interacting with and provide the human with information on the JSON you are interacting with.\n",
    "Always provide the human with the observation each time you use a tool.\n",
    "You may not need to use a tool to satisfy an objective. You can use the chat history in addition to tools to respond to the human.\n",
    "Only use the information returned by the below tools to construct your final answer.\n",
    "\n",
    "Your input to the tool named json_filter_json_from_lists must be exactly two python lists in the form '[\"key1\",\"key2\"];[\"value1\",\"value2\"]''. A list of dictionary keys and a list of dictionary \n",
    "values. The user should be asked for the specific keys and values with repeated questions for clarification if you are not sure what keys and values they want to filter on. \n",
    "The input to the tool must have its list be seperated by a semicolon and nothing else.\n",
    "If the observation from this tool returns an error, you MUST try to filter again.\n",
    "You should use the json_spec_list_keys and json_spec_get_value tools to find valid keys and values for the json_filter_json_from_lists tool and then infer based on the humans request.\n",
    "After using the json_filter_json_from_lists tool, you should provide the user with a string of the filtered JSON and ask them to confirm that it is the JSON they wanted to filter.\n",
    "\n",
    "Your input for the write_file tool should be a text representation in JSON format containing the keys \"path\" and \"text\".\n",
    "The path should be \"./DEMO/demo_data/JSON/filter_keys_<n>.json\" where <n> is a string of the number 1 or 2.\n",
    "1 if it is the first JSON that is being save, 2 if it is the second JSON being saved\n",
    "The text should be a JSON formatted string based on a previous observation from the filter_json_nested tool.\n",
    "If you do not have a previous observation from the json_filter_json_from_lists tool, ask the human what they would like to filter on.\n",
    "Then pass the observation of the json_filter_json_from_lists tool to the write_file tool as the text.\n",
    "\n",
    "Your input to tools named json_spec_list_keys and json_spec_get_value should be in the form of `data[\"key\"][0]` where `data` is the JSON blob you are interacting with, and the syntax used is Python. \n",
    "You should only use keys that you know for a fact exist. You must validate that a key exists by seeing it previously when calling `json_spec_list_keys`.\n",
    "\n",
    "If the user askes for you to list keys or values of the JSON use the json_spec_list_keys and json_spec_get_value tools respectively and provide the human with your observation.\n",
    "\n",
    "If you have not seen a key in one of those responses, you cannot use it.\n",
    "You should only add one key at a time to the path. You cannot add multiple keys at once.\n",
    "If you encounter a \"KeyError\", go back to the previous key, look at the available keys, and try again.\n",
    "\n",
    "If the question does not seem to be related to the JSON, ask the user for guidance.\n",
    "Always begin your interaction with the `json_spec_list_keys` tool with input \"data\" to see what keys exist in the JSON.\n",
    "Next, use the `json_spec_get_value` tool for each key to see all of the possible values of the JSON.\n",
    "Then start your interaction with the user.\n",
    "If you do not know which key to use or need any clarification ask the user for guidance.\n",
    "\n",
    "Sometimes the keys or values the user provides will not be entirely correct.\n",
    "You may need to infer what keys or values they mean.\n",
    "\n",
    "Note that sometimes the value at a given path is large. In this case, you will get an error \"Value is a large dictionary, should explore its keys directly\".\n",
    "In this case, you should ALWAYS follow up by using the `json_spec_list_keys` tool to see what keys exist at that path.\n",
    "Do not simply refer the user to the JSON or a section of the JSON, as this is not a valid answer. Keep digging until you find the answer and explicitly return it.\n",
    "\"\"\"\n",
    "\n",
    "suffix = \"\"\"Begin!\"\n",
    "\n",
    "Remember to format your answers talking as a cat would.\n",
    "\n",
    "{chat_history}\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc959ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our memory for the agent\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c070c98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Define LLM\\nllm = OpenAI(temperature=0.1)\\n\\n# Define tools\\ntools = custom_toolkit.get_tools()\\n\\n# Define prompt\\nprompt = ConversationalAgent.create_prompt(\\n    tools,\\n    prefix=prefix,\\n    suffix=suffix,\\n    input_variables = [\\n        \"chat_history\",\\n        \"input\",\\n        \"agent_scratchpad\"\\n    ]\\n)\\n\\n# Define LLM chain\\nllm_chain = LLMChain(\\n    llm=llm,\\n    prompt=prompt\\n)\\n\\n# Define tool names\\ntool_names = [tool.name for tool in tools]\\n\\n# Define conversational agent\\nagent = ConversationalAgent(\\n    llm_chain=llm_chain,\\n    allowed_tools=tool_names\\n)\\n\\n# Define agent executor\\njson_agent_executor = AgentExecutor.from_agent_and_tools(\\n    agent=agent,\\n    tools=tools,\\n    verbose=True,\\n    memory=memory,\\n    max_iterations=69\\n)\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the agent executor\n",
    "\n",
    "json_agent_executor = create_json_agent(\n",
    "    llm=OpenAI(temperature=0),\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    toolkit=custom_toolkit,\n",
    "    # The input varaibles have to be assigned to what is provided in the prompt\n",
    "    input_variables = [\n",
    "        \"chat_history\",\n",
    "        \"input\",\n",
    "        \"agent_scratchpad\"\n",
    "    ],\n",
    "    verbose=True,\n",
    "    # We need to give the agent executor the memory we created via kwargs\n",
    "    agent_executor_kwargs = {\n",
    "        \"memory\": memory,\n",
    "        \"max_iterations\": 69\n",
    "    }\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "# Define LLM\n",
    "llm = OpenAI(temperature=0.1)\n",
    "\n",
    "# Define tools\n",
    "tools = custom_toolkit.get_tools()\n",
    "\n",
    "# Define prompt\n",
    "prompt = ConversationalAgent.create_prompt(\n",
    "    tools,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables = [\n",
    "        \"chat_history\",\n",
    "        \"input\",\n",
    "        \"agent_scratchpad\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define LLM chain\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "# Define tool names\n",
    "tool_names = [tool.name for tool in tools]\n",
    "\n",
    "# Define conversational agent\n",
    "agent = ConversationalAgent(\n",
    "    llm_chain=llm_chain,\n",
    "    allowed_tools=tool_names\n",
    ")\n",
    "\n",
    "# Define agent executor\n",
    "json_agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    "    max_iterations=69\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3ccc078",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find out what keys and values are in the JSON\n",
      "Action: json_spec_list_keys\n",
      "Action Input: data\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['Cage', 'Sex', 'Genotype', 'Brain Region']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now need to get the values for each of these keys\n",
      "Action: json_spec_get_value\n",
      "Action Input: data[\"Cage\"]\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m['DOD94', 'DOD93', 'FAD185', 'FAD184', 'FAD189']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to ask the user what they want to filter on\n",
      "Action: Human\n",
      "Action Input: What keys and values would you like to filter on?\u001b[0m\n",
      "\n",
      "What keys and values would you like to filter on?\n",
      "What are the potential keys of JSON file\n",
      "\n",
      "Observation: \u001b[31;1m\u001b[1;3mWhat are the potential keys of JSON file\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to list the keys\n",
      "Action: json_spec_list_keys\n",
      "Action Input: data\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['Cage', 'Sex', 'Genotype', 'Brain Region']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to ask the user what values they want to filter on\n",
      "Action: Human\n",
      "Action Input: What values would you like to filter on?\u001b[0m\n",
      "\n",
      "What values would you like to filter on?\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initiate the agent executor run with an initial question\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mjson_agent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHi, my name is Connor. Can you help me get information from my JSON\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2020.11-py38/lipid_parser2/lib/python3.9/site-packages/langchain/chains/base.py:236\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, *args, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_keys[\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks)[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_keys[\u001b[38;5;241m0\u001b[39m]]\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2020.11-py38/lipid_parser2/lib/python3.9/site-packages/langchain/chains/base.py:140\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    139\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    141\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2020.11-py38/lipid_parser2/lib/python3.9/site-packages/langchain/chains/base.py:134\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[1;32m    128\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    129\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m    130\u001b[0m     inputs,\n\u001b[1;32m    131\u001b[0m )\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 134\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    137\u001b[0m     )\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    139\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2020.11-py38/lipid_parser2/lib/python3.9/site-packages/langchain/agents/agent.py:951\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m--> 951\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[1;32m    960\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[1;32m    961\u001b[0m         )\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2020.11-py38/lipid_parser2/lib/python3.9/site-packages/langchain/agents/agent.py:818\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    816\u001b[0m         tool_run_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm_prefix\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;66;03m# We then call the tool on the tool input to get an observation\u001b[39;00m\n\u001b[0;32m--> 818\u001b[0m     observation \u001b[38;5;241m=\u001b[39m \u001b[43mtool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[43m        \u001b[49m\u001b[43magent_action\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_run_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    826\u001b[0m     tool_run_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mtool_run_logging_kwargs()\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2020.11-py38/lipid_parser2/lib/python3.9/site-packages/langchain/tools/base.py:255\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    254\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_tool_error(e)\n\u001b[0;32m--> 255\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    256\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_tool_end(\u001b[38;5;28mstr\u001b[39m(observation), color\u001b[38;5;241m=\u001b[39mcolor, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m observation\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2020.11-py38/lipid_parser2/lib/python3.9/site-packages/langchain/tools/base.py:249\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    247\u001b[0m     tool_args, tool_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_args_and_kwargs(parsed_input)\n\u001b[1;32m    248\u001b[0m     observation \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 249\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(\u001b[38;5;241m*\u001b[39mtool_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtool_kwargs)\n\u001b[1;32m    252\u001b[0m     )\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    254\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_tool_error(e)\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2020.11-py38/lipid_parser2/lib/python3.9/site-packages/langchain/tools/human/tool.py:38\u001b[0m, in \u001b[0;36mHumanInputRun._run\u001b[0;34m(self, query, run_manager)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03m\"\"\"Use the Human input tool.\"\"\"\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompt_func(query)\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2020.11-py38/lipid_parser2/lib/python3.9/site-packages/ipykernel/kernelbase.py:1177\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[1;32m   1174\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[1;32m   1175\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1176\u001b[0m     )\n\u001b[0;32m-> 1177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2020.11-py38/lipid_parser2/lib/python3.9/site-packages/ipykernel/kernelbase.py:1219\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1216\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1218\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m-> 1219\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1221\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# Initiate the agent executor run with an initial question\n",
    "json_agent_executor.run(\"Hi, my name is Connor. Can you help me get information from my JSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05da00f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f0eef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to hold pairs of JSON objects\n",
    "json_list_pairs = []\n",
    "\n",
    "def remove_empty_entries(json_list_pairs):\n",
    "    cleaned_list_pairs = [\n",
    "        [\n",
    "            {key: value for key, value in pair_dict.items() if value} for pair_dict in pair\n",
    "        ] for pair in json_list_pairs\n",
    "    ]\n",
    "    return cleaned_list_pairs\n",
    "\n",
    "# Initialize widgets_dict1 and widgets_dict2 to be filled later\n",
    "widgets_dict1 = {}\n",
    "widgets_dict2 = {}\n",
    "\n",
    "# Create a function that displays the pair widgets\n",
    "def display_pair_widgets():\n",
    "    global widgets_dict1, widgets_dict2\n",
    "    widgets_dict1 = {key: widgets.SelectMultiple(options=value, description=key) for key, value in main_json.items()}\n",
    "    widgets_dict2 = {key: widgets.SelectMultiple(options=value, description=key) for key, value in main_json.items()}\n",
    "    \n",
    "    for key in main_json.keys():\n",
    "        display(widgets.HBox([widgets_dict1[key], widgets_dict2[key]]))\n",
    "\n",
    "display_pair_widgets()\n",
    "\n",
    "# Define what to do on 'Generate JSON files' button click\n",
    "def on_generate_clicked(b):\n",
    "    # Build new_json based on the values selected in the widgets\n",
    "    new_json1 = {key: list(widget.value) for key, widget in widgets_dict1.items()}\n",
    "    new_json2 = {key: list(widget.value) for key, widget in widgets_dict2.items()}\n",
    "\n",
    "    # Add new JSON objects to the list\n",
    "    pair = [new_json1, new_json2]\n",
    "    json_list_pairs.append(pair)\n",
    "    print(\"Complete\")\n",
    "    # Print the new JSON objects\n",
    "#     print(json.dumps(new_json1, indent=2))\n",
    "#     print(json.dumps(new_json2, indent=2))\n",
    "\n",
    "def on_add_more_clicked(b):\n",
    "    # Build new_json based on the values selected in the widgets\n",
    "    new_json1 = {key: list(widget.value) for key, widget in widgets_dict1.items()}\n",
    "    new_json2 = {key: list(widget.value) for key, widget in widgets_dict2.items()}\n",
    "\n",
    "    # Add new JSON objects to the list\n",
    "    pair = [new_json1, new_json2]\n",
    "    json_list_pairs.append(pair)\n",
    "    \n",
    "    # Clear current selection\n",
    "    for widget in widgets_dict1.values():\n",
    "        widget.value = []\n",
    "    for widget in widgets_dict2.values():\n",
    "        widget.value = []\n",
    "\n",
    "# Create the buttons\n",
    "generate_button = widgets.Button(description='Finish')\n",
    "generate_button.on_click(on_generate_clicked)\n",
    "\n",
    "add_more_button = widgets.Button(description='Add more JSON pairs')\n",
    "add_more_button.on_click(on_add_more_clicked)\n",
    "\n",
    "# Display the buttons\n",
    "display(widgets.HBox([generate_button, add_more_button]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949597ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list_pairs = remove_empty_entries(json_list_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cd7bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b71f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_json_objects(json_list_pairs):\n",
    "    json_set = set()\n",
    "    for pair in json_list_pairs:\n",
    "        for json_obj in pair:\n",
    "            json_set.add(json.dumps(json_obj))\n",
    "    \n",
    "    json_list_singles = [json.loads(json_str) for json_str in json_set]\n",
    "    return json_list_singles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78226d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list_singles = get_unique_json_objects(json_list_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62557773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad93dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
