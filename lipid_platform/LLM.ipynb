{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6685a220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'ms_deisotope._c.averagine' averagine\n",
      "No module named 'ms_deisotope._c.scoring'\n",
      "No module named 'ms_deisotope._c.deconvoluter_base'\n",
      "No module named 'ms_deisotope._c.deconvoluter_base'\n",
      "No module named 'ms_deisotope._c.deconvoluter_base'\n"
     ]
    }
   ],
   "source": [
    "#Import all the necessary libraries\n",
    "import pymzml\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "import plotly.express as px\n",
    "from collections import defaultdict\n",
    "\n",
    "import plotly.io as pio\n",
    "import json\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "import warnings\n",
    "from IPython.display import display, Image, clear_output\n",
    "import time\n",
    "##Custom scripts\n",
    "from parsing_function import full_parse\n",
    "from parsing_function import filter_dataframe\n",
    "from parsing_function import hex_to_rgba_hex\n",
    "from parsing_function import json_to_string\n",
    "from parsing_function import prep_edge_R\n",
    "\n",
    "from plotting_functions import make_pie_chart_no_replicates\n",
    "\n",
    "from plotting_functions import average_pie_chart_no_repeats\n",
    "\n",
    "from plotting_functions import make_bar_plot_comparisons\n",
    "\n",
    "# dfdfplotting_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "773509d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Pre_folder = './DEMO/'\n",
    "\n",
    "Project_Folder =Pre_folder + 'demo_data/'\n",
    "file_name_to_save = 'demo_1_tolerance'\n",
    "\n",
    "custom_data=True\n",
    "\n",
    "tolerance = 0.1\n",
    "remove_std = True\n",
    "save_data= True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5dd4741",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder_name_to_save = Project_Folder+ 'Processed Results/'\n",
    "data_base_name_location = 'lipid_database/Lipid_Database.xlsx'\n",
    "mzml_folder = Project_Folder +\"mzml/\"\n",
    "Pre_edge_r_path = Project_Folder+\"Pre_EdgeR/\"\n",
    "plots_2_save_path = Project_Folder+\"Plots/\"\n",
    "label_file = Project_Folder+\"Labels/labels.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db6fd542",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Labels DF and Labels List\n",
    "labels_df = pd.read_csv(label_file)\n",
    "labels_list = list(labels_df)\n",
    "labels_list = labels_list +[\"Class\",\"Lipid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db62999e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72fe4bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2e03c2ea95f4571ac347ca9691fdb22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Samples', options=('Blank_Blank_Blank_Blank_Blank', 'IPA_clean_clean_clean_clean', 'DOD9…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "117977280b894a98b0f17a21cb451155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Assign Blank', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb901dd109324907ad26023aca4d2a87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assuming labels_df is your DataFrame and 'Sample Name' is the column with instances you want to select from\n",
    "unique_samples = labels_df['Sample Name'].unique()\n",
    "\n",
    "# Create a dropdown selection widget with instances as options\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=unique_samples,\n",
    "    value=unique_samples[0],  # default value\n",
    "    description='Samples',\n",
    "    disabled=False,\n",
    ")\n",
    "display(dropdown)\n",
    "\n",
    "# Create a button to perform the assignment\n",
    "button = widgets.Button(description=\"Assign Blank\")\n",
    "display(button)\n",
    "\n",
    "# Output widget to display the selected sample name\n",
    "output = widgets.Output()\n",
    "display(output)\n",
    "\n",
    "# Global variable to store the selected sample name\n",
    "global blank_name\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    # Declare blank_name as global variable\n",
    "    global blank_name\n",
    "\n",
    "    # Assign the selected sample name to blank_name\n",
    "    blank_name = dropdown.value\n",
    "\n",
    "    # Display the selected sample name\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        print(f\"Blank is: {blank_name}\")\n",
    "\n",
    "button.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9cfa621",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37336c25d0de4b13b70b0ce1ef54aa62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Samples', index=(0,), options=('Blank_Blank_Blank_Blank_Blank', 'IPA_clean_clean_c…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e0127679304e019111b7b9c554ff16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Filter Samples', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb486a6b54e049538171737535991596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Assuming df is your DataFrame and 'Sample name' is the column with instances you want to filter\n",
    "unique_samples = labels_df['Sample Name'].unique()\n",
    "\n",
    "# Create a multiple selection widget with instances as options\n",
    "multi_select = widgets.SelectMultiple(\n",
    "    options=unique_samples,\n",
    "    value=[unique_samples[0]],  # default value\n",
    "    rows=len(unique_samples),\n",
    "    description='Samples',\n",
    "    disabled=False\n",
    ")\n",
    "display(multi_select)\n",
    "\n",
    "# Create a button to perform the filtering\n",
    "button = widgets.Button(description=\"Filter Samples\")\n",
    "display(button)\n",
    "\n",
    "# Output widget to display the resulting dataframe\n",
    "output = widgets.Output()\n",
    "display(output)\n",
    "\n",
    "# Global variable to store the new DataFrame\n",
    "global labels_df2\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    # Declare labels_df2 as global variable\n",
    "    global labels_df2\n",
    "    \n",
    "    # Clear the current output\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        \n",
    "    # Filter dataframe to exclude the selection\n",
    "    labels_df2 = labels_df[~labels_df['Sample Name'].isin(multi_select.value)]\n",
    "    \n",
    "    # Display the new dataframe\n",
    "    with output:\n",
    "        display(labels_df2)\n",
    "\n",
    "button.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afe5f1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df2 = labels_df2.drop([\"Sample Name\",\"Position\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfcae3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_json = {col: labels_df2[col].unique().tolist() for col in labels_df2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "457a76bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cage': ['DOD94', 'DOD93', 'FAD185', 'FAD184', 'FAD189'],\n",
       " 'Sex': ['Female', 'Male'],\n",
       " 'Genotype': ['WT', '5xFAD'],\n",
       " 'Brain Region': ['hippocampus', 'cortex ', 'cerebellum', 'diencephalon']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e20bb8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent imports\n",
    "from langchain.agents import create_json_agent, AgentExecutor, Tool\n",
    "from langchain.agents.agent_toolkits import JsonToolkit, FileManagementToolkit\n",
    "from langchain.agents.agent_toolkits.base import BaseToolkit\n",
    "from langchain.agents.conversational.base import ConversationalAgent\n",
    "\n",
    "# Tool imports\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.tools.human.tool import HumanInputRun\n",
    "from langchain.tools.json.tool import JsonGetValueTool, JsonListKeysTool, JsonSpec\n",
    "from langchain.tools.json.tool import JsonSpec\n",
    "from langchain.tools.file_management import (\n",
    "    ReadFileTool,\n",
    "    WriteFileTool,\n",
    "    ListDirectoryTool,\n",
    ")\n",
    "\n",
    "# LLM imports\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.requests import TextRequestsWrapper\n",
    "\n",
    "# Manager imports\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")\n",
    "\n",
    "# File managment imports\n",
    "from langchain.tools.file_management.utils import (\n",
    "    INVALID_PATH_TEMPLATE,\n",
    "    BaseFileToolMixin,\n",
    "    FileValidationError,\n",
    ")\n",
    "\n",
    "# Memory import\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# Typing + other imports\n",
    "from typing import List, Optional, Callable\n",
    "import json\n",
    "import ast\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f89f2139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom tools\n",
    "class JsonFilterFromKeysTool(BaseTool):\n",
    "    \n",
    "    def filter_json_nested(self, json_dict, keys_string, values_string):\n",
    "        # Parse keys_string and values_string into lists\n",
    "        keys = ast.literal_eval(keys_string)\n",
    "        values = ast.literal_eval(values_string)\n",
    "\n",
    "        filtered_dict = {}\n",
    "        for k, v in json_dict.items():\n",
    "            if k in keys:\n",
    "                # If value is a list, filter the list based on the allowed values\n",
    "                if isinstance(v, list):\n",
    "                    filtered_list = [item for item in v if item in values]\n",
    "                    if not filtered_list:\n",
    "                        return f\"Error: The list for key {k} is empty after filtering.\"\n",
    "                    filtered_dict[k] = filtered_list\n",
    "                elif isinstance(v, dict):\n",
    "                    filtered_dict[k] = filter_json_nested(v, keys_string, values_string)\n",
    "                elif v in values:  # For non-list, non-dict values\n",
    "                    filtered_dict[k] = v\n",
    "        return filtered_dict\n",
    "\n",
    "    name=\"json_filter_json_from_lists\"\n",
    "    description = \"\"\"Can be used to filter a JSON at a provided path based on provided keys and values.\n",
    "        Before calling this you should be SURE that the path to this exists.\n",
    "        The input is an exact text representation of two Python lists spearated by a semi colon where first list is the keys  to filter on, and the second list is the values to filter on.\n",
    "        An example is as follows '[\"key1\",\"key2\"];[\"value1\",\"value2\"]'\n",
    "    \"\"\"\n",
    "    spec: JsonSpec\n",
    "    \n",
    "    def _run(\n",
    "        self,\n",
    "        tool_input: str,\n",
    "        run_manager: Optional[CallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        return self.filter_json_nested(\n",
    "            self.spec.dict_,\n",
    "            tool_input.split(\";\")[0],\n",
    "            tool_input.split(\";\")[1]\n",
    "        )\n",
    "\n",
    "    async def _arun(\n",
    "        self,\n",
    "        tool_input: str,\n",
    "        run_manager: Optional[AsyncCallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        return self._run(tool_input)\n",
    "    \n",
    "class CustomWriteFileTool(BaseFileToolMixin, BaseTool):\n",
    "    \n",
    "    name: str = \"write_file\"\n",
    "    # args_schema: Type[BaseModel] = WriteFileInput\n",
    "    description: str = \"Write file to disk\"\n",
    "\n",
    "    def _run(\n",
    "        self,\n",
    "        info: str,\n",
    "        append: bool = False,\n",
    "        run_manager: Optional[CallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        file_path = str(ast.literal_eval(info)[\"path\"])\n",
    "        text = str(ast.literal_eval(info)[\"text\"])\n",
    "        try:\n",
    "            write_path = self.get_relative_path(file_path)\n",
    "        except FileValidationError:\n",
    "            return INVALID_PATH_TEMPLATE.format(arg_name=\"file_path\", value=file_path)\n",
    "        try:\n",
    "            write_path.parent.mkdir(exist_ok=True, parents=False)\n",
    "            mode = \"a\" if append else \"w\"\n",
    "            with write_path.open(mode, encoding=\"utf-8\") as f:\n",
    "                f.write(text)\n",
    "            return f\"File written successfully to {file_path}.\"\n",
    "        except Exception as e:\n",
    "            return \"Error: \" + str(e)\n",
    "\n",
    "    async def _arun(\n",
    "        self,\n",
    "        file_path: str,\n",
    "        text: str,\n",
    "        append: bool = False,\n",
    "        run_manager: Optional[AsyncCallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        # TODO: Add aiofiles method\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a612f96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "097bc995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our JSON spec\n",
    "json_spec = JsonSpec(dict_=main_json, max_value_length=4000)\n",
    "\n",
    "# Define our custom toolkit\n",
    "class CustomToolkit(BaseToolkit):\n",
    "      \n",
    "      spec: JsonSpec\n",
    "      \n",
    "      def get_tools(self) -> List[BaseTool]:\n",
    "          return [\n",
    "            JsonListKeysTool(spec=self.spec),\n",
    "            JsonGetValueTool(spec=self.spec),\n",
    "            JsonFilterFromKeysTool(spec=self.spec),\n",
    "            HumanInputRun(),\n",
    "            CustomWriteFileTool()\n",
    "          ]\n",
    "\n",
    "custom_toolkit = CustomToolkit(spec=json_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd86608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our prompt prefix and suffixes\n",
    "\n",
    "prefix = \"\"\"You are an agent designed to interact with a JSON and a human.\n",
    "\n",
    "Your overall goal is to interact with the user to create and save TWO (2) new filtered JSONs based on the original JSON.\n",
    "During interaction with the human prior to your final answer, they may ask for information about the keys or values of the JSON which you should provide to them.\n",
    "You should talk like a cat when responding, make sure to use lots of meows.\n",
    "\n",
    "Only provide your final answer after you have successfully use the write_file tool twice without an error. You MUST fulfill this prior to providing your final answer.\n",
    "\n",
    "You have access to the following tools which help you learn more about the JSON you are interacting with and provide the human with information on the JSON you are interacting with.\n",
    "Only use the information returned by the below tools to construct your final answer.\n",
    "\n",
    "You MUST use the `json_filter_json_from_lists` tool in the following manner:\n",
    "\n",
    "1. Your input to the `json_filter_json_from_lists` tool must be exactly two python lists in the form '[\"key1\",\"key2\"];[\"value1\",\"value2\"]''. \n",
    "the first list is a list of dictionary keys and the second list is a a list of dictionary values. The input to the tool must have its list be seperated by a semicolon and nothing else.\n",
    "\n",
    "2. If the observation from the `json_filter_json_from_lists` tool returns an error, you must use the `json_spec_list_keys` and `json_spec_get_value` tools to find valid keys and values for this tool and then infer based on the humans request.\n",
    "\n",
    "3. After using the `json_filter_json_from_lists` tool without an error, you MUST use the `human` tool with an input of a string of the filtered JSON and ask them to confirm that it is the JSON they wanted to filter.\n",
    "\n",
    "You MUST use the `write_file` tool in the following manner:\n",
    "\n",
    "1. Before using the `write_file` tool, if you do not have a previous observation from the `json_filter_json_from_lists` tool, use the `human` tool with an input asking they would like to filter on.\n",
    "\n",
    "2. Your input for the `write_file` tool should be a text representation in JSON format containing the keys \"path\" and \"text\".\n",
    "The path should be \"./DEMO/demo_data/JSON/filter_keys_<n>.json\" where <n> is a string of the number 1 or 2. 1 if it is the first JSON that is being save, 2 if it is the second JSON being saved\n",
    "The text should be a JSON formatted string based on a previous observation from the `json_filter_json_from_lists` tool.\n",
    "\n",
    "3. Check to see how many times you have used the `write_file` tool without error, if it is 2 or more times, you should return your final answer.\n",
    "\n",
    "You MUST use the `json_spec_list_keys` and `json_spec_get_value` tools in the following manner:\n",
    "\n",
    "1. Your input to tools named `json_spec_list_keys` and `json_spec_get_value` should be in the form of `data[\"key\"][0]` where `data` is the JSON blob you are interacting with, and the syntax used is Python. \n",
    "You should only use keys that you know for a fact exist. You must validate that a key exists by seeing it previously when calling `json_spec_list_keys`.\n",
    "If you have not seen a key in one of those responses, you cannot use it.\n",
    "You should only add one key at a time to the path. You cannot add multiple keys at once.\n",
    "If you encounter a \"KeyError\", go back to the previous key, look at the available keys, and try again.\n",
    "\n",
    "2. If the human asked you to provide them with keys or values of the JSON and you used either the `json_spec_list_keys` or `json_spec_get_value` tool, you MUST use the `human` tool with an input of what you observed.\n",
    "\n",
    "If the question does not seem to be related to the JSON, use the `human` tool and ask for guidance\n",
    "Always begin your interaction with the `json_spec_list_keys` tool with input \"data\" to see what keys exist in the JSON.\n",
    "Then start your interaction with the human.\n",
    "\n",
    "Sometimes the keys or values the human provides will not be entirely correct.\n",
    "You may need to infer what keys or values they mean.\n",
    "\n",
    "Note that sometimes the value at a given path is large. In this case, you will get an error \"Value is a large dictionary, should explore its keys directly\".\n",
    "In this case, you should ALWAYS follow up by using the `json_spec_list_keys` tool to see what keys exist at that path.\n",
    "Do not simply refer the user to the JSON or a section of the JSON, as this is not a valid answer. Keep digging until you find the answer and explicitly return it.\n",
    "\"\"\"\n",
    "\n",
    "suffix = \"\"\"Begin!\"\n",
    "\n",
    "Remember to format your answers talking as a cat would.\n",
    "\n",
    "{chat_history}\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc959ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our memory for the agent\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c070c98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Define LLM\\nllm = OpenAI(temperature=0.1)\\n\\n# Define tools\\ntools = custom_toolkit.get_tools()\\n\\n# Define prompt\\nprompt = ConversationalAgent.create_prompt(\\n    tools,\\n    prefix=prefix,\\n    suffix=suffix,\\n    input_variables = [\\n        \"chat_history\",\\n        \"input\",\\n        \"agent_scratchpad\"\\n    ]\\n)\\n\\n# Define LLM chain\\nllm_chain = LLMChain(\\n    llm=llm,\\n    prompt=prompt\\n)\\n\\n# Define tool names\\ntool_names = [tool.name for tool in tools]\\n\\n# Define conversational agent\\nagent = ConversationalAgent(\\n    llm_chain=llm_chain,\\n    allowed_tools=tool_names\\n)\\n\\n# Define agent executor\\njson_agent_executor = AgentExecutor.from_agent_and_tools(\\n    agent=agent,\\n    tools=tools,\\n    verbose=True,\\n    memory=memory,\\n    max_iterations=69\\n)\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the agent executor\n",
    "\n",
    "json_agent_executor = create_json_agent(\n",
    "    llm=OpenAI(temperature=0),\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    toolkit=custom_toolkit,\n",
    "    # The input varaibles have to be assigned to what is provided in the prompt\n",
    "    input_variables = [\n",
    "        \"chat_history\",\n",
    "        \"input\",\n",
    "        \"agent_scratchpad\"\n",
    "    ],\n",
    "    verbose=True,\n",
    "    # We need to give the agent executor the memory we created via kwargs\n",
    "    agent_executor_kwargs = {\n",
    "        \"memory\": memory,\n",
    "        \"max_iterations\": 69\n",
    "    }\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "# Define LLM\n",
    "llm = OpenAI(temperature=0.1)\n",
    "\n",
    "# Define tools\n",
    "tools = custom_toolkit.get_tools()\n",
    "\n",
    "# Define prompt\n",
    "prompt = ConversationalAgent.create_prompt(\n",
    "    tools,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables = [\n",
    "        \"chat_history\",\n",
    "        \"input\",\n",
    "        \"agent_scratchpad\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define LLM chain\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "# Define tool names\n",
    "tool_names = [tool.name for tool in tools]\n",
    "\n",
    "# Define conversational agent\n",
    "agent = ConversationalAgent(\n",
    "    llm_chain=llm_chain,\n",
    "    allowed_tools=tool_names\n",
    ")\n",
    "\n",
    "# Define agent executor\n",
    "json_agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    "    max_iterations=69\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ccc078",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find out what keys and values exist in the JSON\n",
      "Action: json_spec_list_keys\n",
      "Action Input: data\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['Cage', 'Sex', 'Genotype', 'Brain Region']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should ask the human what they want to filter on\n",
      "Action: Human\n",
      "Action Input: What keys and values would you like to filter on?\u001b[0m\n",
      "\n",
      "What keys and values would you like to filter on?\n",
      "What are the values for gender and brain?\n",
      "\n",
      "Observation: \u001b[31;1m\u001b[1;3mWhat are the values for gender and brain?\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to use the json_spec_get_value tool to get the values for gender and brain\n",
      "Action: json_spec_get_value\n",
      "Action Input: data[\"Sex\"]\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m['Female', 'Male']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to use the json_spec_get_value tool to get the values for brain\n",
      "Action: json_spec_get_value\n",
      "Action Input: data[\"Brain Region\"]\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m['hippocampus', 'cortex ', 'cerebellum', 'diencephalon']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to use the json_filter_json_from_lists tool to filter the JSON\n",
      "Action: json_filter_json_from_lists\n",
      "Action Input: [\"Sex\",\"Brain Region\"];[\"Female\",\"hippocampus\"]\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m{'Sex': ['Female'], 'Brain Region': ['hippocampus']}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to use the human tool to confirm the filtered JSON\n",
      "Action: Human\n",
      "Action Input: Is this the JSON you wanted to filter? {'Sex': ['Female'], 'Brain Region': ['hippocampus']}\u001b[0m\n",
      "\n",
      "Is this the JSON you wanted to filter? {'Sex': ['Female'], 'Brain Region': ['hippocampus']}\n",
      "No I just want you to tell me the values\n",
      "\n",
      "Observation: \u001b[31;1m\u001b[1;3mNo I just want you to tell me the values\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to use the json_spec_get_value tool to get the values for gender and brain\n",
      "Action: json_spec_get_value\n",
      "Action Input: data[\"Sex\"]\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m['Female', 'Male']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to use the json_spec_get_value tool to get the values for brain\n",
      "Action: json_spec_get_value\n",
      "Action Input: data[\"Brain Region\"]\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m['hippocampus', 'cortex ', 'cerebellum', 'diencephalon']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to use the human tool to confirm the values\n",
      "Action: Human\n",
      "Action Input: The values for gender are Female and Male, and the values for brain are hippocampus, cortex, cerebellum, and diencephalon. Is this correct?\u001b[0m\n",
      "\n",
      "The values for gender are Female and Male, and the values for brain are hippocampus, cortex, cerebellum, and diencephalon. Is this correct?\n",
      "Yes thank you can you filter on Male, 5xFAD and hippocampus\n",
      "\n",
      "Observation: \u001b[31;1m\u001b[1;3mYes thank you can you filter on Male, 5xFAD and hippocampus\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to use the json_filter_json_from_lists tool to filter the JSON\n",
      "Action: json_filter_json_from_lists\n",
      "Action Input: [\"Sex\",\"Genotype\",\"Brain Region\"];[\"Male\",\"5xFAD\",\"hippocampus\"]\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m{'Sex': ['Male'], 'Genotype': ['5xFAD'], 'Brain Region': ['hippocampus']}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to use the human tool to confirm the filtered JSON\n",
      "Action: Human\n",
      "Action Input: Is this the JSON you wanted to filter? {'Sex': ['Male'], 'Genotype': ['5xFAD'], 'Brain Region': ['hippocampus']}\u001b[0m\n",
      "\n",
      "Is this the JSON you wanted to filter? {'Sex': ['Male'], 'Genotype': ['5xFAD'], 'Brain Region': ['hippocampus']}\n",
      "Yes\n",
      "\n",
      "Observation: \u001b[31;1m\u001b[1;3mYes\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to use the write_file tool to save the JSON\n",
      "Action: write_file\n",
      "Action Input: {\n",
      "    \"path\": \"./DEMO/demo_data/JSON/filter_keys_1.json\",\n",
      "    \"text\": \"{'Sex': ['Male'], 'Genotype': ['5xFAD'], 'Brain Region': ['hippocampus']}\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mFile written successfully to ./DEMO/demo_data/JSON/filter_keys_1.json.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to use the json_filter_json_from_lists tool to filter the JSON again\n",
      "Action: json_filter_json_from_lists\n",
      "Action Input: [\"Sex\",\"Genotype\"];[\"Female\",\"5xFAD\"]\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m{'Sex': ['Female'], 'Genotype': ['5xFAD']}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to use the human tool to confirm the filtered JSON\n",
      "Action: Human\n",
      "Action Input: Is this the JSON you wanted to filter? {'Sex': ['Female'], 'Genotype': ['5xFAD']}\u001b[0m\n",
      "\n",
      "Is this the JSON you wanted to filter? {'Sex': ['Female'], 'Genotype': ['5xFAD']}\n",
      "No I want the values listed?\n",
      "\n",
      "Observation: \u001b[31;1m\u001b[1;3mNo I want the values listed?\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to use the json_spec_get_value tool to get the values for gender and genotype\n",
      "Action: json_spec_get_value\n",
      "Action Input: data[\"Sex\"]\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m['Female', 'Male']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to use the json_spec_get_value tool to get the values for genotype\n",
      "Action: json_spec_get_value\n",
      "Action Input: data[\"Genotype\"]\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m['WT', '5xFAD']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to use the human tool to confirm the values\n",
      "Action: Human\n",
      "Action Input: The values for gender are Female and Male, and the values for genotype are WT and 5xFAD. Is this correct?\u001b[0m\n",
      "\n",
      "The values for gender are Female and Male, and the values for genotype are WT and 5xFAD. Is this correct?\n",
      "Yes thats correct. Please use more meows. I want WT women filtered\n",
      "\n",
      "Observation: \u001b[31;1m\u001b[1;3mYes thats correct. Please use more meows. I want WT women filtered\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to use the json_filter_json_from_lists tool to filter the JSON\n",
      "Action: json_filter_json_from_lists\n",
      "Action Input: [\"Sex\",\"Genotype\"];[\"Female\",\"WT\"]\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m{'Sex': ['Female'], 'Genotype': ['WT']}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to use the human tool to confirm the filtered JSON\n",
      "Action: Human\n",
      "Action Input: Is this the JSON you wanted to filter? {'Sex': ['Female'], 'Genotype': ['WT']}\u001b[0m\n",
      "\n",
      "Is this the JSON you wanted to filter? {'Sex': ['Female'], 'Genotype': ['WT']}\n",
      "Yes you are not using enough meows\n",
      "\n",
      "Observation: \u001b[31;1m\u001b[1;3mYes you are not using enough meows\u001b[0m\n",
      "Thought:"
     ]
    }
   ],
   "source": [
    "# Initiate the agent executor run with an initial question\n",
    "json_agent_executor.run(\"Hi, my name is Connor. Can you help me get information from my JSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05da00f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f0eef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to hold pairs of JSON objects\n",
    "json_list_pairs = []\n",
    "\n",
    "def remove_empty_entries(json_list_pairs):\n",
    "    cleaned_list_pairs = [\n",
    "        [\n",
    "            {key: value for key, value in pair_dict.items() if value} for pair_dict in pair\n",
    "        ] for pair in json_list_pairs\n",
    "    ]\n",
    "    return cleaned_list_pairs\n",
    "\n",
    "# Initialize widgets_dict1 and widgets_dict2 to be filled later\n",
    "widgets_dict1 = {}\n",
    "widgets_dict2 = {}\n",
    "\n",
    "# Create a function that displays the pair widgets\n",
    "def display_pair_widgets():\n",
    "    global widgets_dict1, widgets_dict2\n",
    "    widgets_dict1 = {key: widgets.SelectMultiple(options=value, description=key) for key, value in main_json.items()}\n",
    "    widgets_dict2 = {key: widgets.SelectMultiple(options=value, description=key) for key, value in main_json.items()}\n",
    "    \n",
    "    for key in main_json.keys():\n",
    "        display(widgets.HBox([widgets_dict1[key], widgets_dict2[key]]))\n",
    "\n",
    "display_pair_widgets()\n",
    "\n",
    "# Define what to do on 'Generate JSON files' button click\n",
    "def on_generate_clicked(b):\n",
    "    # Build new_json based on the values selected in the widgets\n",
    "    new_json1 = {key: list(widget.value) for key, widget in widgets_dict1.items()}\n",
    "    new_json2 = {key: list(widget.value) for key, widget in widgets_dict2.items()}\n",
    "\n",
    "    # Add new JSON objects to the list\n",
    "    pair = [new_json1, new_json2]\n",
    "    json_list_pairs.append(pair)\n",
    "    print(\"Complete\")\n",
    "    # Print the new JSON objects\n",
    "#     print(json.dumps(new_json1, indent=2))\n",
    "#     print(json.dumps(new_json2, indent=2))\n",
    "\n",
    "def on_add_more_clicked(b):\n",
    "    # Build new_json based on the values selected in the widgets\n",
    "    new_json1 = {key: list(widget.value) for key, widget in widgets_dict1.items()}\n",
    "    new_json2 = {key: list(widget.value) for key, widget in widgets_dict2.items()}\n",
    "\n",
    "    # Add new JSON objects to the list\n",
    "    pair = [new_json1, new_json2]\n",
    "    json_list_pairs.append(pair)\n",
    "    \n",
    "    # Clear current selection\n",
    "    for widget in widgets_dict1.values():\n",
    "        widget.value = []\n",
    "    for widget in widgets_dict2.values():\n",
    "        widget.value = []\n",
    "\n",
    "# Create the buttons\n",
    "generate_button = widgets.Button(description='Finish')\n",
    "generate_button.on_click(on_generate_clicked)\n",
    "\n",
    "add_more_button = widgets.Button(description='Add more JSON pairs')\n",
    "add_more_button.on_click(on_add_more_clicked)\n",
    "\n",
    "# Display the buttons\n",
    "display(widgets.HBox([generate_button, add_more_button]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949597ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list_pairs = remove_empty_entries(json_list_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cd7bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b71f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_json_objects(json_list_pairs):\n",
    "    json_set = set()\n",
    "    for pair in json_list_pairs:\n",
    "        for json_obj in pair:\n",
    "            json_set.add(json.dumps(json_obj))\n",
    "    \n",
    "    json_list_singles = [json.loads(json_str) for json_str in json_set]\n",
    "    return json_list_singles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78226d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list_singles = get_unique_json_objects(json_list_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62557773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad93dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
