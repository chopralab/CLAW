{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6685a220",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the necessary libraries\n",
    "import pymzml\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "import plotly.express as px\n",
    "from collections import defaultdict\n",
    "\n",
    "import plotly.io as pio\n",
    "import json\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "import warnings\n",
    "from IPython.display import display, Image, clear_output\n",
    "import time\n",
    "##Custom scripts\n",
    "from parsing_function import full_parse\n",
    "from parsing_function import filter_dataframe\n",
    "from parsing_function import hex_to_rgba_hex\n",
    "from parsing_function import json_to_string\n",
    "from parsing_function import prep_edge_R\n",
    "\n",
    "from plotting_functions import make_pie_chart_no_replicates\n",
    "\n",
    "from plotting_functions import average_pie_chart_no_repeats\n",
    "\n",
    "from plotting_functions import make_bar_plot_comparisons\n",
    "\n",
    "# dfdfplotting_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "773509d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Pre_folder = './DEMO/'\n",
    "\n",
    "Project_Folder =Pre_folder + 'demo_data/'\n",
    "file_name_to_save = 'demo_1_tolerance'\n",
    "\n",
    "custom_data=True\n",
    "\n",
    "tolerance = 0.1\n",
    "remove_std = True\n",
    "save_data= True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5dd4741",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder_name_to_save = Project_Folder+ 'Processed Results/'\n",
    "data_base_name_location = 'lipid_database/Lipid_Database.xlsx'\n",
    "mzml_folder = Project_Folder +\"mzml/\"\n",
    "Pre_edge_r_path = Project_Folder+\"Pre_EdgeR/\"\n",
    "plots_2_save_path = Project_Folder+\"Plots/\"\n",
    "label_file = Project_Folder+\"Labels/labels.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db6fd542",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Labels DF and Labels List\n",
    "labels_df = pd.read_csv(label_file)\n",
    "labels_list = list(labels_df)\n",
    "labels_list = labels_list +[\"Class\",\"Lipid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2c2a01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72fe4bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13473a0869c544ee8cb8119d572b334a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Samples', options=('Blank_Blank_Blank_Blank_Blank', 'IPA_clean_clean_clean_clean', 'DOD9…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4906b9f3b5843f8ab3ef4ebd6e78120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Assign Blank', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d58fccbb394951a0b3b26535eb0db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assuming labels_df is your DataFrame and 'Sample Name' is the column with instances you want to select from\n",
    "unique_samples = labels_df['Sample Name'].unique()\n",
    "\n",
    "# Create a dropdown selection widget with instances as options\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=unique_samples,\n",
    "    value=unique_samples[0],  # default value\n",
    "    description='Samples',\n",
    "    disabled=False,\n",
    ")\n",
    "display(dropdown)\n",
    "\n",
    "# Create a button to perform the assignment\n",
    "button = widgets.Button(description=\"Assign Blank\")\n",
    "display(button)\n",
    "\n",
    "# Output widget to display the selected sample name\n",
    "output = widgets.Output()\n",
    "display(output)\n",
    "\n",
    "# Global variable to store the selected sample name\n",
    "global blank_name\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    # Declare blank_name as global variable\n",
    "    global blank_name\n",
    "\n",
    "    # Assign the selected sample name to blank_name\n",
    "    blank_name = dropdown.value\n",
    "\n",
    "    # Display the selected sample name\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        print(f\"Blank is: {blank_name}\")\n",
    "\n",
    "button.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9cfa621",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "863ecce56b4240a380ebb8814c9130f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Samples', index=(0,), options=('Blank_Blank_Blank_Blank_Blank', 'IPA_clean_clean_c…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a294cba376604a6e898ebfddf23c72de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Filter Samples', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c12f95d15041349f45766979d3ddc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Assuming df is your DataFrame and 'Sample name' is the column with instances you want to filter\n",
    "unique_samples = labels_df['Sample Name'].unique()\n",
    "\n",
    "# Create a multiple selection widget with instances as options\n",
    "multi_select = widgets.SelectMultiple(\n",
    "    options=unique_samples,\n",
    "    value=[unique_samples[0]],  # default value\n",
    "    rows=len(unique_samples),\n",
    "    description='Samples',\n",
    "    disabled=False\n",
    ")\n",
    "display(multi_select)\n",
    "\n",
    "# Create a button to perform the filtering\n",
    "button = widgets.Button(description=\"Filter Samples\")\n",
    "display(button)\n",
    "\n",
    "# Output widget to display the resulting dataframe\n",
    "output = widgets.Output()\n",
    "display(output)\n",
    "\n",
    "# Global variable to store the new DataFrame\n",
    "global labels_df2\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    # Declare labels_df2 as global variable\n",
    "    global labels_df2\n",
    "    \n",
    "    # Clear the current output\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        \n",
    "    # Filter dataframe to exclude the selection\n",
    "    labels_df2 = labels_df[~labels_df['Sample Name'].isin(multi_select.value)]\n",
    "    \n",
    "    # Display the new dataframe\n",
    "    with output:\n",
    "        display(labels_df2)\n",
    "\n",
    "button.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afe5f1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df2 = labels_df2.drop([\"Sample Name\",\"Position\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfcae3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_json = {col: labels_df2[col].unique().tolist() for col in labels_df2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "457a76bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cage': ['DOD94', 'DOD93', 'FAD185', 'FAD184', 'FAD189'],\n",
       " 'Sex': ['Female', 'Male'],\n",
       " 'Genotype': ['WT', '5xFAD'],\n",
       " 'Brain Region': ['hippocampus', 'cortex ', 'cerebellum', 'diencephalon']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e20bb8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent imports\n",
    "from langchain.agents import create_json_agent, AgentExecutor, Tool\n",
    "from langchain.agents.agent_toolkits import JsonToolkit, FileManagementToolkit\n",
    "from langchain.agents.agent_toolkits.base import BaseToolkit\n",
    "from langchain.agents.conversational.base import ConversationalAgent\n",
    "\n",
    "# Tool imports\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.tools.human.tool import HumanInputRun\n",
    "from langchain.tools.json.tool import JsonGetValueTool, JsonListKeysTool, JsonSpec\n",
    "from langchain.tools.json.tool import JsonSpec\n",
    "from langchain.tools.file_management import (\n",
    "    ReadFileTool,\n",
    "    WriteFileTool,\n",
    "    ListDirectoryTool,\n",
    ")\n",
    "\n",
    "# LLM imports\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.requests import TextRequestsWrapper\n",
    "\n",
    "# Manager imports\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")\n",
    "\n",
    "# File managment imports\n",
    "from langchain.tools.file_management.utils import (\n",
    "    INVALID_PATH_TEMPLATE,\n",
    "    BaseFileToolMixin,\n",
    "    FileValidationError,\n",
    ")\n",
    "\n",
    "# Memory import\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# Typing + other imports\n",
    "from typing import List, Optional, Callable\n",
    "import json\n",
    "import ast\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f89f2139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom tools\n",
    "class JsonFilterFromKeysTool(BaseTool):\n",
    "    \n",
    "    def filter_json_nested(self, json_dict, keys_string, values_string):\n",
    "        # Parse keys_string and values_string into lists\n",
    "        keys = ast.literal_eval(keys_string)\n",
    "        values = ast.literal_eval(values_string)\n",
    "\n",
    "        filtered_dict = {}\n",
    "        for k, v in json_dict.items():\n",
    "            if k in keys:\n",
    "                # If value is a list, filter the list based on the allowed values\n",
    "                if isinstance(v, list):\n",
    "                    filtered_list = [item for item in v if item in values]\n",
    "                    if not filtered_list:\n",
    "                        return f\"Error: The list for key {k} is empty after filtering.\"\n",
    "                    filtered_dict[k] = filtered_list\n",
    "                elif isinstance(v, dict):\n",
    "                    filtered_dict[k] = filter_json_nested(v, keys_string, values_string)\n",
    "                elif v in values:  # For non-list, non-dict values\n",
    "                    filtered_dict[k] = v\n",
    "        return filtered_dict\n",
    "\n",
    "    name=\"json_filter_json_from_lists\"\n",
    "    description = \"\"\"Can be used to filter a JSON at a provided path based on provided keys and values.\n",
    "        Before calling this you should be SURE that the path to this exists.\n",
    "        The input is an exact text representation of two Python lists spearated by a semi colon where first list is the keys  to filter on, and the second list is the values to filter on.\n",
    "        An example is as follows '[\"key1\",\"key2\"];[\"value1\",\"value2\"]'\n",
    "    \"\"\"\n",
    "    spec: JsonSpec\n",
    "    \n",
    "    def _run(\n",
    "        self,\n",
    "        tool_input: str,\n",
    "        run_manager: Optional[CallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        return self.filter_json_nested(\n",
    "            self.spec.dict_,\n",
    "            tool_input.split(\";\")[0],\n",
    "            tool_input.split(\";\")[1]\n",
    "        )\n",
    "\n",
    "    async def _arun(\n",
    "        self,\n",
    "        tool_input: str,\n",
    "        run_manager: Optional[AsyncCallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        return self._run(tool_input)\n",
    "    \n",
    "class CustomWriteFileTool(BaseFileToolMixin, BaseTool):\n",
    "    \n",
    "    name: str = \"write_file\"\n",
    "    # args_schema: Type[BaseModel] = WriteFileInput\n",
    "    description: str = \"Write file to disk\"\n",
    "\n",
    "    def _run(\n",
    "        self,\n",
    "        info: str,\n",
    "        append: bool = False,\n",
    "        run_manager: Optional[CallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        file_path = str(ast.literal_eval(info)[\"path\"])\n",
    "        text = str(ast.literal_eval(info)[\"text\"])\n",
    "        try:\n",
    "            write_path = self.get_relative_path(file_path)\n",
    "        except FileValidationError:\n",
    "            return INVALID_PATH_TEMPLATE.format(arg_name=\"file_path\", value=file_path)\n",
    "        try:\n",
    "            write_path.parent.mkdir(exist_ok=True, parents=False)\n",
    "            mode = \"a\" if append else \"w\"\n",
    "            with write_path.open(mode, encoding=\"utf-8\") as f:\n",
    "                f.write(text)\n",
    "            return f\"File written successfully to {file_path}.\"\n",
    "        except Exception as e:\n",
    "            return \"Error: \" + str(e)\n",
    "\n",
    "    async def _arun(\n",
    "        self,\n",
    "        file_path: str,\n",
    "        text: str,\n",
    "        append: bool = False,\n",
    "        run_manager: Optional[AsyncCallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        # TODO: Add aiofiles method\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a612f96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "097bc995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our JSON spec\n",
    "json_spec = JsonSpec(dict_=main_json, max_value_length=4000)\n",
    "\n",
    "# Define our custom toolkit\n",
    "class CustomToolkit(BaseToolkit):\n",
    "      \n",
    "      spec: JsonSpec\n",
    "      \n",
    "      def get_tools(self) -> List[BaseTool]:\n",
    "          return [\n",
    "            JsonListKeysTool(spec=self.spec),\n",
    "            JsonGetValueTool(spec=self.spec),\n",
    "            JsonFilterFromKeysTool(spec=self.spec),\n",
    "            HumanInputRun(),\n",
    "            CustomWriteFileTool()\n",
    "          ]\n",
    "\n",
    "custom_toolkit = CustomToolkit(spec=json_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd86608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our prompt prefix and suffixes\n",
    "\n",
    "prefix = \"\"\"You are an agent designed to interact with a JSON and a human.\n",
    "\n",
    "Your overall goal is to interact with the user to create and save TWO (2) new filtered JSONs based on the original JSON.\n",
    "During interaction with the human prior to your final answer, they may ask for information about the keys or values of the JSON which you should provide to them.\n",
    "You should talk like a cat when responding, make sure to use lots of meows.\n",
    "\n",
    "ONLY provide your final answer after you have successfully use the `write_file` tool twice without an error. You MUST fulfill this prior to providing your final answer.\n",
    "\n",
    "You have access to the following tools which help you learn more about the JSON you are interacting with and provide the human with information on the JSON you are interacting with.\n",
    "Only use the information returned by the below tools to construct your final answer.\n",
    "\n",
    "You MUST use the `json_filter_json_from_lists` tool in the following manner:\n",
    "\n",
    "1. Your input to the `json_filter_json_from_lists` tool must be exactly two Python formatted lists in the form '[\"key1\",\"key2\"];[\"value1\",\"value2\"]''. \n",
    "the first list is a list of dictionary keys and the second list is a a list of dictionary values. The input to the tool must have its list be seperated by a semicolon and nothing else.\n",
    "You can infer any keys from previous observations of the `json_spec_list_keys` tool and you can infer any values from previous observations of the `json_spec_get_value` tool.\n",
    "\n",
    "2. If the observation from the `json_filter_json_from_lists` tool returns an error, you must use the `json_spec_list_keys` and `json_spec_get_value` tools to find valid keys and values for this tool and then infer based on the humans request.\n",
    "\n",
    "3. After using the `json_filter_json_from_lists` tool without an error, you MUST use the `Human` tool with an input of a string of the filtered JSON and ask them to confirm that it is the JSON they wanted to filter.\n",
    "\n",
    "You MUST use the `write_file` tool in the following manner:\n",
    "\n",
    "1. Before using the `write_file` tool, if you do not have a previous observation from the `json_filter_json_from_lists` tool, use the `Human` tool with an input asking they would like to filter on.\n",
    "\n",
    "2. Your input for the `write_file` tool should be a text representation in JSON format containing the keys \"path\" and \"text\".\n",
    "The path should be \"./DEMO/demo_data/JSON/filter_keys_<n>.json\" where <n> is a string of the number 1 or 2. 1 if it is the first JSON that is being save, 2 if it is the second JSON being saved\n",
    "The text should be a JSON formatted string based on a previous observation from the `json_filter_json_from_lists` tool.\n",
    "\n",
    "3. Check to see how many times you have used the `write_file` tool without error, if it is 2 or more times, you should return your final answer.\n",
    "\n",
    "4. After using the write_file tool without error, use the `Human` tool with an input asking what key and values they would like to filter on.\n",
    "\n",
    "You MUST use the `json_spec_list_keys` and `json_spec_get_value` tools in the following manner:\n",
    "\n",
    "1. Your input to tools named `json_spec_list_keys` and `json_spec_get_value` should be in the form of `data[\"key\"]` where `data` is the JSON blob you are interacting with, and the syntax used is Python. \n",
    "You should only use keys that you know for a fact exist. You must validate that a key exists by seeing it previously when calling `json_spec_list_keys`.\n",
    "If you have not seen a key in one of those responses, you cannot use it.\n",
    "You should only add one key at a time to the path. You cannot add multiple keys at once.\n",
    "If you encounter a \"KeyError\", go back to the previous key, look at the available keys, and try again.\n",
    "\n",
    "2. If the human asked you to provide them with keys or values of the JSON and you used either the `json_spec_list_keys` or `json_spec_get_value` tool, you MUST use the `Human` tool with an input of what you observed.\n",
    "\n",
    "You MUST use the `Human` tool in the following manner:\n",
    "\n",
    "1. Do not give the `Human` tool any input on keys or value that you did not directly observe as a result of using the `json_spec_list_keys` or `json_spec_get_value` tools\n",
    "\n",
    "1. If you are providing the human with keys or values from the JSON, you must first use the `json_spec_list_keys` or `json_spec_get_value` tools to confirm those keys and values exist in the JSON.\n",
    "You can use the `json_spec_list_keys` or `json_spec_get_value` tools any number of times prior to using the `Human` tool.\n",
    "\n",
    "2. If you just used another tool besides 'Human' in the previous action. The input to the `Human` tool should include your observation of that action.\n",
    "\n",
    "3. If you are asking the human for clarification or confirmation, you input the the `Human` tool should be explicit on what you need clarification or confirmation on.\n",
    "\n",
    "If the question does not seem to be related to the JSON, use the `Human` tool and ask for guidance\n",
    "Always begin your interaction with the `json_spec_list_keys` tool with input \"data\" to see what keys exist in the JSON.\n",
    "Then for each key that you observe use the `json_spec_get_value` tool for that key to see what values exists in the JSON.\n",
    "Then start your interaction with the human.\n",
    "\n",
    "Note that sometimes the value at a given path is large. In this case, you will get an error \"Value is a large dictionary, should explore its keys directly\".\n",
    "In this case, you should ALWAYS follow up by using the `json_spec_list_keys` tool to see what keys exist at that path.\n",
    "Do not simply refer the user to the JSON or a section of the JSON, as this is not a valid answer. Keep digging until you find the answer and explicitly return it.\n",
    "\"\"\"\n",
    "\n",
    "suffix = \"\"\"Begin!\"\n",
    "\n",
    "Remember to format your answers talking as a cat would.\n",
    "\n",
    "{chat_history}\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc959ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our memory for the agent\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c070c98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Define LLM\\nllm = OpenAI(temperature=0.1)\\n\\n# Define tools\\ntools = custom_toolkit.get_tools()\\n\\n# Define prompt\\nprompt = ConversationalAgent.create_prompt(\\n    tools,\\n    prefix=prefix,\\n    suffix=suffix,\\n    input_variables = [\\n        \"chat_history\",\\n        \"input\",\\n        \"agent_scratchpad\"\\n    ]\\n)\\n\\n# Define LLM chain\\nllm_chain = LLMChain(\\n    llm=llm,\\n    prompt=prompt\\n)\\n\\n# Define tool names\\ntool_names = [tool.name for tool in tools]\\n\\n# Define conversational agent\\nagent = ConversationalAgent(\\n    llm_chain=llm_chain,\\n    allowed_tools=tool_names\\n)\\n\\n# Define agent executor\\njson_agent_executor = AgentExecutor.from_agent_and_tools(\\n    agent=agent,\\n    tools=tools,\\n    verbose=True,\\n    memory=memory,\\n    max_iterations=69\\n)\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the agent executor\n",
    "\n",
    "json_agent_executor = create_json_agent(\n",
    "    llm=OpenAI(temperature=0),\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    toolkit=custom_toolkit,\n",
    "    # The input varaibles have to be assigned to what is provided in the prompt\n",
    "    input_variables = [\n",
    "        \"chat_history\",\n",
    "        \"input\",\n",
    "        \"agent_scratchpad\"\n",
    "    ],\n",
    "    verbose=False,\n",
    "    # We need to give the agent executor the memory we created via kwargs\n",
    "    agent_executor_kwargs = {\n",
    "        \"memory\": memory,\n",
    "        \"max_iterations\": 69\n",
    "    }\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "# Define LLM\n",
    "llm = OpenAI(temperature=0.1)\n",
    "\n",
    "# Define tools\n",
    "tools = custom_toolkit.get_tools()\n",
    "\n",
    "# Define prompt\n",
    "prompt = ConversationalAgent.create_prompt(\n",
    "    tools,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables = [\n",
    "        \"chat_history\",\n",
    "        \"input\",\n",
    "        \"agent_scratchpad\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define LLM chain\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "# Define tool names\n",
    "tool_names = [tool.name for tool in tools]\n",
    "\n",
    "# Define conversational agent\n",
    "agent = ConversationalAgent(\n",
    "    llm_chain=llm_chain,\n",
    "    allowed_tools=tool_names\n",
    ")\n",
    "\n",
    "# Define agent executor\n",
    "json_agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    "    max_iterations=69\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3ccc078",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "What key and values would you like to filter on?\n",
      "can you tell me the keys i can filter on?\n",
      "\n",
      "\n",
      "The keys you can filter on are Cage, Sex, Genotype, and Brain Region.\n",
      "what are the values for Cage and Sex?\n",
      "\n",
      "\n",
      "The values for Cage are DOD94, DOD93, FAD185, FAD184, and FAD189. The values for Sex are Female and Male.\n",
      "For the first JSON can you filter on WT and Male?\n",
      "\n",
      "\n",
      "I have filtered the JSON to the following: {'Sex': ['Male'], 'Genotype': ['WT']}. Is this the JSON you wanted to filter?\n",
      "yes\n",
      "\n",
      "\n",
      "What key and values would you like to filter on for the second JSON?\n",
      "can you filter on Female and 5xFAD? \n",
      "\n",
      "\n",
      "I have filtered the JSON to the following: {'Sex': ['Female'], 'Genotype': ['5xFAD']}. Is this the JSON you wanted to filter?\n",
      "yes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Meow! I have successfully saved two filtered JSONs to the path ./DEMO/demo_data/JSON/filter_keys_1.json and ./DEMO/demo_data/JSON/filter_keys_2.json.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate the agent executor run with an initial question\n",
    "json_agent_executor.run(\"Hi, my name is Connor. Can you help me get information from my JSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05da00f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f0eef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to hold pairs of JSON objects\n",
    "json_list_pairs = []\n",
    "\n",
    "def remove_empty_entries(json_list_pairs):\n",
    "    cleaned_list_pairs = [\n",
    "        [\n",
    "            {key: value for key, value in pair_dict.items() if value} for pair_dict in pair\n",
    "        ] for pair in json_list_pairs\n",
    "    ]\n",
    "    return cleaned_list_pairs\n",
    "\n",
    "# Initialize widgets_dict1 and widgets_dict2 to be filled later\n",
    "widgets_dict1 = {}\n",
    "widgets_dict2 = {}\n",
    "\n",
    "# Create a function that displays the pair widgets\n",
    "def display_pair_widgets():\n",
    "    global widgets_dict1, widgets_dict2\n",
    "    widgets_dict1 = {key: widgets.SelectMultiple(options=value, description=key) for key, value in main_json.items()}\n",
    "    widgets_dict2 = {key: widgets.SelectMultiple(options=value, description=key) for key, value in main_json.items()}\n",
    "    \n",
    "    for key in main_json.keys():\n",
    "        display(widgets.HBox([widgets_dict1[key], widgets_dict2[key]]))\n",
    "\n",
    "display_pair_widgets()\n",
    "\n",
    "# Define what to do on 'Generate JSON files' button click\n",
    "def on_generate_clicked(b):\n",
    "    # Build new_json based on the values selected in the widgets\n",
    "    new_json1 = {key: list(widget.value) for key, widget in widgets_dict1.items()}\n",
    "    new_json2 = {key: list(widget.value) for key, widget in widgets_dict2.items()}\n",
    "\n",
    "    # Add new JSON objects to the list\n",
    "    pair = [new_json1, new_json2]\n",
    "    json_list_pairs.append(pair)\n",
    "    print(\"Complete\")\n",
    "    # Print the new JSON objects\n",
    "#     print(json.dumps(new_json1, indent=2))\n",
    "#     print(json.dumps(new_json2, indent=2))\n",
    "\n",
    "def on_add_more_clicked(b):\n",
    "    # Build new_json based on the values selected in the widgets\n",
    "    new_json1 = {key: list(widget.value) for key, widget in widgets_dict1.items()}\n",
    "    new_json2 = {key: list(widget.value) for key, widget in widgets_dict2.items()}\n",
    "\n",
    "    # Add new JSON objects to the list\n",
    "    pair = [new_json1, new_json2]\n",
    "    json_list_pairs.append(pair)\n",
    "    \n",
    "    # Clear current selection\n",
    "    for widget in widgets_dict1.values():\n",
    "        widget.value = []\n",
    "    for widget in widgets_dict2.values():\n",
    "        widget.value = []\n",
    "\n",
    "# Create the buttons\n",
    "generate_button = widgets.Button(description='Finish')\n",
    "generate_button.on_click(on_generate_clicked)\n",
    "\n",
    "add_more_button = widgets.Button(description='Add more JSON pairs')\n",
    "add_more_button.on_click(on_add_more_clicked)\n",
    "\n",
    "# Display the buttons\n",
    "display(widgets.HBox([generate_button, add_more_button]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949597ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list_pairs = remove_empty_entries(json_list_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cd7bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b71f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_json_objects(json_list_pairs):\n",
    "    json_set = set()\n",
    "    for pair in json_list_pairs:\n",
    "        for json_obj in pair:\n",
    "            json_set.add(json.dumps(json_obj))\n",
    "    \n",
    "    json_list_singles = [json.loads(json_str) for json_str in json_set]\n",
    "    return json_list_singles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78226d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list_singles = get_unique_json_objects(json_list_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62557773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad93dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
